{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<font size = 10>\r\n",
    "\r\n",
    "# pimm依赖"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ***data系列***"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font size = 3>\r\n",
    "\r\n",
    "### pimm.data.Dataset 与 pimm.data.create_loader"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - import测试"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from Paddle_Cream.lib.utils.pimm.data import Dataset, create_loader"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - 测试主要方法与函数运行"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset_eval = Dataset(\"Cream/data/imagenet/val\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "loader_eval = create_loader(\r\n",
    "        dataset_eval,\r\n",
    "        input_size = (3, 224, 224),\r\n",
    "        batch_size = 4 * 32,\r\n",
    "        is_training = True,\r\n",
    "        num_workers = 4,\r\n",
    "        distributed = False,\r\n",
    "        interpolation = 'bicubic',\r\n",
    "        crop_pct = 0.875,\r\n",
    "        mean = (0.485, 0.456, 0.406),\r\n",
    "        std = (0.229, 0.224, 0.225))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - 输出值测试"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for _, (input, _) in enumerate(loader_eval):\r\n",
    "    break\r\n",
    "print(input)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ***loss系列***"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font size = \"3\">\r\n",
    "\r\n",
    "### pimm.loss.LabelSmoothingCrossEntropy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - import测试"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from Paddle_Cream.lib.utils.pimm.loss import LabelSmoothingCrossEntropy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - 测试方法创建"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd_fun = LabelSmoothingCrossEntropy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - 前向对齐测试"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "output = np.random.rand(100,20)\r\n",
    "target = np.random.randint(low = 0, high = 20, size = (100))\r\n",
    "for i in range(100):\r\n",
    "    output[i][target[i]] += 10\r\n",
    "    output[i] /= output[i].sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import paddle\r\n",
    "pd_loss = pd_fun(\r\n",
    "    paddle.to_tensor(output, dtype = \"float32\"), \r\n",
    "    paddle.to_tensor(target))\r\n",
    "print(pd_loss)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\r\n",
    "    def __init__(self, smoothing=0.1):\r\n",
    "        super(LabelSmoothingCrossEntropy, self).__init__()\r\n",
    "        assert smoothing < 1.0\r\n",
    "        self.smoothing = smoothing\r\n",
    "        self.confidence = 1. - smoothing\r\n",
    "\r\n",
    "    def forward(self, x, target):\r\n",
    "        logprobs = F.log_softmax(x, dim=-1)\r\n",
    "        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\r\n",
    "        nll_loss = nll_loss.squeeze(1)\r\n",
    "        smooth_loss = -logprobs.mean(dim=-1)\r\n",
    "        loss = self.confidence * nll_loss + self.smoothing * smooth_loss\r\n",
    "        return loss.mean()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "index = torch.from_numpy(target).type_as(torch.zeros((2,2), dtype = torch.int64))\r\n",
    "tc_loss = LabelSmoothingCrossEntropy()(\r\n",
    "    torch.from_numpy(output), \r\n",
    "    index)\r\n",
    "print(tc_loss)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ***models.effcientnet_blocks系列***"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - import测试"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from Paddle_Cream.lib.utils.pimm.models.efficientnet_blocks import ConvBnAct, DepthwiseSeparableConv, drop_path, InvertedResidual,SqueezeExcite"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font size = 3>\r\n",
    "\r\n",
    "### pimm.models.effcientnet_blocks.ConvBnAct"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - 网络创建"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "conv_bn_act = ConvBnAct(in_chs = 3, out_chs = 8, kernel_size = 3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - 网络组网与运行测试"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import paddle\r\n",
    "conv_bn_act_model = paddle.Model(conv_bn_act)\r\n",
    "conv_bn_act_model.summary(input_size = (10, 3, 224, 224))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class ConvBnAct_Model(paddle.nn.Layer):\r\n",
    "    def __init__(self) -> None:\r\n",
    "        super(ConvBnAct_Model, self).__init__()\r\n",
    "        self.core = ConvBnAct(in_chs = 3, out_chs = 8, kernel_size = 3)\r\n",
    "    \r\n",
    "    @paddle.jit.to_static\r\n",
    "    def forward(self, x):\r\n",
    "        return self.core(x)\r\n",
    "\r\n",
    "conv_bn_act_model = ConvBnAct_Model()\r\n",
    "conv_bn_act_model.eval()\r\n",
    "\r\n",
    "conv_bn_act_model(paddle.randn((10, 3, 224, 224)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font size = 3>\r\n",
    "\r\n",
    "### pimm.models.effcientnet_blocks.DepthwiseSeparableConv"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - 网络创建"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dsc = DepthwiseSeparableConv(in_chs = 8, out_chs = 3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - 网络组网与运行测试"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import paddle\r\n",
    "dsc_model = paddle.Model(dsc)\r\n",
    "dsc_model.summary(input_size = (1, 8, 224, 224))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import paddle\r\n",
    "class DSC_Model(paddle.nn.Layer):\r\n",
    "    def __init__(self) -> None:\r\n",
    "        super(DSC_Model, self).__init__()\r\n",
    "        self.core = DepthwiseSeparableConv(in_chs = 8, out_chs = 3)\r\n",
    "    \r\n",
    "    @paddle.jit.to_static\r\n",
    "    def forward(self, x):\r\n",
    "        return self.core(x)\r\n",
    "\r\n",
    "dsc_model = DSC_Model()\r\n",
    "dsc_model.eval()\r\n",
    "\r\n",
    "dsc_model(paddle.randn((10, 8, 224, 224)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font size = 3>\r\n",
    "\r\n",
    "### pimm.models.effcientnet_blocks.drop_path"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import paddle\r\n",
    "test_Tensor = paddle.randn((16, 3, 224, 224))\r\n",
    "drop_path(test_Tensor)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font size = 3>\r\n",
    "\r\n",
    "### pimm.models.effcientnet_blocks.InvertedResidual"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - 网络创建"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ir = InvertedResidual(in_chs = 8, out_chs = 3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - 网络组网与运行测试"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import paddle\r\n",
    "ir_model = paddle.Model(ir)\r\n",
    "ir_model.summary(input_size = (16, 8, 224, 224))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import paddle\r\n",
    "class IR_Model(paddle.nn.Layer):\r\n",
    "    def __init__(self) -> None:\r\n",
    "        super(IR_Model, self).__init__()\r\n",
    "        self.core = InvertedResidual(in_chs = 8, out_chs = 3)\r\n",
    "    \r\n",
    "    @paddle.jit.to_static\r\n",
    "    def forward(self, x):\r\n",
    "        return self.core(x)\r\n",
    "\r\n",
    "ir_model = IR_Model()\r\n",
    "ir_model.eval()\r\n",
    "\r\n",
    "ir_model(paddle.randn((16, 8, 224, 224)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font size = 3>\r\n",
    "\r\n",
    "### pimm.models.effcientnet_blocks.SqueezeExcite"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - 网络创建"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "se = SqueezeExcite(in_chs = 8)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - 网络组网与运行测试"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import paddle\r\n",
    "se_model = paddle.Model(se)\r\n",
    "se_model.summary(input_size = (16, 8, 224, 224))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import paddle\r\n",
    "class SE_Model(paddle.nn.Layer):\r\n",
    "    def __init__(self) -> None:\r\n",
    "        super(SE_Model, self).__init__()\r\n",
    "        self.core = SqueezeExcite(in_chs = 8)\r\n",
    "    \r\n",
    "    @paddle.jit.to_static\r\n",
    "    def forward(self, x):\r\n",
    "        return self.core(x)\r\n",
    "\r\n",
    "se_model = SE_Model()\r\n",
    "se_model.eval()\r\n",
    "\r\n",
    "se_model(paddle.randn((16, 8, 224, 224)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ***models.activations系列***"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - import测试"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from Paddle_Cream.lib.utils.pimm.models.activations import hard_sigmoid, Swish"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font size = 3>\r\n",
    "\r\n",
    "### pimm.models.activations.hard_sigmoid"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import paddle\r\n",
    "import numpy as np\r\n",
    "hard_sigmoid(paddle.to_tensor(np.linspace(0., 10.)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font size = 3>\r\n",
    "\r\n",
    "### pimm.models.activations.Swish"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import paddle\r\n",
    "import numpy as np\r\n",
    "swish = Swish()\r\n",
    "swish(paddle.to_tensor(np.linspace(0., 10.)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ***models系列（其他函数与类）***"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font size = 3>\r\n",
    "\r\n",
    "### pimm.models.create_conv2d"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - import测试"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from Paddle_Cream.lib.utils.pimm.models import create_conv2d"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - 调用测试"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Conv_2D = []\r\n",
    "Conv_2D.append(create_conv2d(in_chs = 8, out_chs = 3, kernel_size = [3, 5, 7]))\r\n",
    "Conv_2D.append(create_conv2d(in_chs = 8, out_chs = 3, kernel_size = 5, num_experts = 3))\r\n",
    "Conv_2D.append(create_conv2d(in_chs = 8, out_chs = 3, kernel_size = 5))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - 网络结构检查"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import paddle\r\n",
    "for module in (Conv_2D[0], Conv_2D[2]):\r\n",
    "    model_test = paddle.Model(module)\r\n",
    "    model_test.summary(input_size = (16, 8, 224, 224))\r\n",
    "    del model_test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font size = 3>\r\n",
    "\r\n",
    "### pimm.models.SelectAdaptivePool2D"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - import测试"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from Paddle_Cream.lib.utils.pimm.models import SelectAdaptivePool2D"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - 网络创建"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pools = [\r\n",
    "    SelectAdaptivePool2D(output_size = 10, pool_type = \"avgmax\"), \r\n",
    "    SelectAdaptivePool2D(output_size = 10, pool_type = \"catavgmax\"), \r\n",
    "    SelectAdaptivePool2D(output_size = 10, pool_type = \"avg\"), \r\n",
    "    SelectAdaptivePool2D(output_size = 10, pool_type = \"max\")]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - 网络结构检查"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import paddle\r\n",
    "for layer in pools:\r\n",
    "    model = paddle.Model(layer)\r\n",
    "    model.summary(input_size = (16, 3, 224, 224))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - 网络组网与运行测试"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import paddle\r\n",
    "test_x = paddle.randint(0, 2, (1, 2, 3, 3))\r\n",
    "test_x = paddle.to_tensor(test_x, dtype = \"float32\")\r\n",
    "print(test_x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Pool_Model_1(paddle.nn.Layer):\r\n",
    "    def __init__(self) -> None:\r\n",
    "        super(Pool_Model_1, self).__init__()\r\n",
    "        self.core = SelectAdaptivePool2D(output_size = 10, pool_type = \"avgmax\")\r\n",
    "    \r\n",
    "    @paddle.jit.to_static\r\n",
    "    def forward(self, x):\r\n",
    "        return self.core(x)\r\n",
    "\r\n",
    "class Pool_Model_2(paddle.nn.Layer):\r\n",
    "    def __init__(self) -> None:\r\n",
    "        super(Pool_Model_2, self).__init__()\r\n",
    "        self.core = SelectAdaptivePool2D(output_size = 10, pool_type = \"catavgmax\")\r\n",
    "    \r\n",
    "    @paddle.jit.to_static\r\n",
    "    def forward(self, x):\r\n",
    "        return self.core(x)\r\n",
    "\r\n",
    "class Pool_Model_3(paddle.nn.Layer):\r\n",
    "    def __init__(self) -> None:\r\n",
    "        super(Pool_Model_3, self).__init__()\r\n",
    "        self.core = SelectAdaptivePool2D(output_size = 10, pool_type = \"avg\")\r\n",
    "    \r\n",
    "    @paddle.jit.to_static\r\n",
    "    def forward(self, x):\r\n",
    "        return self.core(x)\r\n",
    "\r\n",
    "class Pool_Model_4(paddle.nn.Layer):\r\n",
    "    def __init__(self) -> None:\r\n",
    "        super(Pool_Model_4, self).__init__()\r\n",
    "        self.core = SelectAdaptivePool2D(output_size = 10, pool_type = \"max\")\r\n",
    "    \r\n",
    "    @paddle.jit.to_static\r\n",
    "    def forward(self, x):\r\n",
    "        return self.core(x)\r\n",
    "\r\n",
    "Pool_Models = [Pool_Model_1, Pool_Model_2, Pool_Model_3, Pool_Model_4]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for test_Model in Pool_Models:\r\n",
    "    model = test_Model()\r\n",
    "    model.eval()\r\n",
    "    print(model(test_x))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font size = 3>\r\n",
    "\r\n",
    "### pimm.models.resume_checkpoint"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "测试此部分前，请先测试`pimm.utils.CheckpointSaver`以生成本部分测试所需要的存档"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - import测试"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from Paddle_Cream.lib.utils.pimm.models import resume_checkpoint"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - 存档载入测试"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from Paddle_Cream.lib.utils.pimm.models import create_conv2d\r\n",
    "test_Model = create_conv2d(in_chs = 8, out_chs = 3, kernel_size = [3, 5, 7])\r\n",
    "\r\n",
    "resume_checkpoint(test_Model, \"test/last.pdparams\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "测试完成后请运行`utils.CheckpointSaver`中的“删除生成文件部分以”删除用于测试的存档"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ***utils系列***"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - import测试"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from Paddle_Cream.lib.utils.pimm.utils import reduce_tensor, CheckpointSaver, ModelEma"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font size = 3>\r\n",
    "\r\n",
    "### pimm.utils.reduce_tensor"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import paddle\r\n",
    "test_Tensor = paddle.randn((3, 3, 3))\r\n",
    "print(test_Tensor)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "reduced_test_Tensor = reduce_tensor(test_Tensor, 3.)\r\n",
    "print(reduced_test_Tensor)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font size = 3>\r\n",
    "\r\n",
    "### pimm.utils.CheckpointSaver"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - 实例化测试"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "saver = CheckpointSaver(checkpoint_dir = \"test\", recovery_dir = \"test\", max_history = 5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - 存储测试"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from Paddle_Cream.lib.utils.pimm.models import create_conv2d\r\n",
    "import paddle\r\n",
    "\r\n",
    "test_Model = create_conv2d(in_chs = 8, out_chs = 3, kernel_size = [3, 5, 7])\r\n",
    "test_Optimizer = paddle.optimizer.Adam(parameters = test_Model.parameters())\r\n",
    "\r\n",
    "class test_Args:\r\n",
    "    def __init__(self):\r\n",
    "        self.model = \"\"\r\n",
    "\r\n",
    "test_args = test_Args()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import random\r\n",
    "for i in range(20):\r\n",
    "    saver.save_checkpoint(\r\n",
    "    model = test_Model, optimizer = test_Optimizer, \r\n",
    "    args = test_args, epoch = i + 1, \r\n",
    "    metric = random.random())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for checkpoint in saver.checkpoint_files:\r\n",
    "    print(checkpoint)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - 删除生成文件（若要测试resume_checkpoint则不运行）"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\r\n",
    "f_dir = os.getcwd()\r\n",
    "l_dir = os.path.join(f_dir, \"test\")\r\n",
    "if os.path.exists(l_dir):\r\n",
    "    lis_dir = os.listdir(l_dir)\r\n",
    "    for tar_dir in lis_dir:\r\n",
    "        os.remove(os.path.join(l_dir, tar_dir))\r\n",
    "    os.removedirs(l_dir)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font size = 3>\r\n",
    "\r\n",
    "### pimm.utils.ModelEma"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - 实例化测试"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from Paddle_Cream.lib.utils.pimm.models import create_conv2d\r\n",
    "ema = ModelEma(\r\n",
    "    create_conv2d(in_chs = 8, out_chs = 3, kernel_size = [3, 5, 7]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - 更新测试"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ema.update(\r\n",
    "    create_conv2d(in_chs = 8, out_chs = 3, kernel_size = [3, 5, 7]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ***optim与scheduler系列***"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font size = 3>\r\n",
    "\r\n",
    "### pimm.optim.create_optimizer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "没有有效的测试方法"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font size = 3>\r\n",
    "\r\n",
    "### pimm.scheduler.create_scheduler"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - import测试"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from Paddle_Cream.lib.utils.pimm.scheduler import create_scheduler"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - 实例化测试"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class test_Args:\r\n",
    "    def __init__(self):\r\n",
    "        self.sched = \"step\"\r\n",
    "        self.lr = .01\r\n",
    "        self.epochs = 200\r\n",
    "        self.decay_epochs = 4\r\n",
    "        self.decay_rate = .1\r\n",
    "        self.warmup_lr = 1e-4\r\n",
    "        self.warmup_epochs = 3\r\n",
    "        self.noise_range = None\r\n",
    "        self.lr_noise_pct = .67\r\n",
    "        self.lr_noise_std = 1.\r\n",
    "        self.seed = 42"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sched, num_epochs = create_scheduler(test_Args())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i in range(20):\r\n",
    "    sched.step(i)\r\n",
    "    print(sched.get_lr())"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.1 64-bit"
  },
  "interpreter": {
   "hash": "9c4178638202bf36d847b6f9758ad492f78e3205c6ec371305eb925a87dfd87d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}